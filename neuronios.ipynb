{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrador\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Administrador\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.5504 - loss: 1.1763 - val_accuracy: 0.6430 - val_loss: 0.6526\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "The layer sequential has never been called and thus has no defined input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 57\u001b[0m\n\u001b[0;32m     53\u001b[0m last_deep_layer_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdense_1\u001b[39m\u001b[38;5;124m'\u001b[39m   \u001b[38;5;66;03m# Última camada densa\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Criar o modelo intermediário\u001b[39;00m\n\u001b[0;32m     56\u001b[0m grad_model \u001b[38;5;241m=\u001b[39m Model(\n\u001b[1;32m---> 57\u001b[0m     inputs\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m,\n\u001b[0;32m     58\u001b[0m     outputs\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     59\u001b[0m         model\u001b[38;5;241m.\u001b[39mget_layer(last_conv_layer_name)\u001b[38;5;241m.\u001b[39moutput,  \u001b[38;5;66;03m# Saída da última camada convolucional\u001b[39;00m\n\u001b[0;32m     60\u001b[0m         model\u001b[38;5;241m.\u001b[39mget_layer(last_deep_layer_name)\u001b[38;5;241m.\u001b[39moutput    \u001b[38;5;66;03m# Saída da última camada densa\u001b[39;00m\n\u001b[0;32m     61\u001b[0m     ]\n\u001b[0;32m     62\u001b[0m )\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Passo 4: Obter e Visualizar as Ativações\u001b[39;00m\n\u001b[0;32m     65\u001b[0m img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Administrador\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\operation.py:268\u001b[0m, in \u001b[0;36mOperation.input\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minput\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    260\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Retrieves the input tensor(s) of a symbolic operation.\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \n\u001b[0;32m    262\u001b[0m \u001b[38;5;124;03m    Only returns the tensor(s) corresponding to the *first time*\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;124;03m        Input tensor or list of input tensors.\u001b[39;00m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_node_attribute_at_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_tensors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Administrador\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\operation.py:299\u001b[0m, in \u001b[0;36mOperation._get_node_attribute_at_index\u001b[1;34m(self, node_index, attr, attr_name)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Private utility to retrieves an attribute (e.g. inputs) from a node.\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \n\u001b[0;32m    285\u001b[0m \u001b[38;5;124;03mThis is used to implement the properties:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;124;03m    The operation's attribute `attr` at the node of index `node_index`.\u001b[39;00m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes:\n\u001b[1;32m--> 299\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has never been called \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand thus has no defined \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    302\u001b[0m     )\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes) \u001b[38;5;241m>\u001b[39m node_index:\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to get \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m at node \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but the operation has only \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m inbound nodes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: The layer sequential has never been called and thus has no defined input."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Passo 1: Carregar e Preparar o Dataset\n",
    "train_dir = 'train'\n",
    "validation_dir = 'test'\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Passo 2: Criar e Treinar o Modelo\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3), name='conv2d_1'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2, name='max_pooling2d_1'),\n",
    "    tf.keras.layers.Flatten(name='flatten_1'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid', name='dense_1')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Treinar o modelo (pelo menos 1 época para inicializar as camadas)\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=1,  # Treinar por pelo menos 1 época\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50\n",
    ")\n",
    "\n",
    "# Passo 3: Criar o Modelo para Visualizar Ativações\n",
    "# Usar os nomes corretos das camadas\n",
    "last_conv_layer_name = 'conv2d_1'  # Última camada convolucional\n",
    "last_deep_layer_name = 'dense_1'   # Última camada densa\n",
    "\n",
    "# Criar o modelo intermediário\n",
    "grad_model = Model(\n",
    "    inputs=model.input,\n",
    "    outputs=[\n",
    "        model.get_layer(last_conv_layer_name).output,  # Saída da última camada convolucional\n",
    "        model.get_layer(last_deep_layer_name).output    # Saída da última camada densa\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Passo 4: Obter e Visualizar as Ativações\n",
    "img_path = '1.jpg'\n",
    "img = image.load_img(img_path, target_size=(150, 150))\n",
    "img_tensor = image.img_to_array(img)\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "img_tensor /= 255.\n",
    "\n",
    "# Obter as ativações\n",
    "conv_output, dense_output = grad_model.predict(img_tensor)\n",
    "\n",
    "# Função para visualizar as ativações\n",
    "def display_activation(activations, col_size, row_size, act_index):\n",
    "    activation = activations[act_index]\n",
    "    activation_index = 0\n",
    "    fig, ax = plt.subplots(row_size, col_size, figsize=(row_size*2.5, col_size*1.5))\n",
    "    for row in range(0, row_size):\n",
    "        for col in range(0, col_size):\n",
    "            ax[row][col].imshow(activation[0, :, :, activation_index], cmap='viridis')\n",
    "            activation_index += 1\n",
    "\n",
    "# Exibir as ativações da última camada convolucional\n",
    "display_activation([conv_output], 4, 8, 0)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
